#LyX file created by tex2lyx 2.0.3
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options false
\language english
\language_package none
\inputencoding auto
\fontencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\paperfontsize default
\spacing single
\use_hyperref 0
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 0
\use_mathdots 0
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard

%!TEX root =article.tex
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

%conclusions
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\end_layout

\begin_layout Standard

The state of the art for travel time estimation has focused on either precise and computationally intensive physical models, or large scale, data-driven approaches. We have presented a novel algorithm for travel time estimation that aims at combining the best of both worlds, by combining physical insights with some scalable algorithms. We model the variability of travel times due to stops at intersections using a 
\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
stopgo
\end_layout

\end_inset

 
\begin_inset space ~

\end_inset

 (to detect stops) and a 
\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
hmm
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

{}
\end_layout

\end_inset

 to learn the spatial dependencies between stop locations. We also take into account the spatio-temporal correlations of travel times due to driving behavior or congestion, using a Gaussian Markov Random Fields. In particular, we present a highly scalable algorithm to train and perform inference on Gaussian Markov Random Fields, when applied on geographs.
\end_layout

\begin_layout Standard

We analyze the accuracy of the model using probe vehicle data collected over the Bay Area of San Francisco, CA. The results underline the importance to take into account the multi-modality of travel times in arterial networks due to the presence of traffic signals. The quality of the results we obtain are competitive with the state of the state of the art in traffic, and also highlight the good scalability of our algorithm.
\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard

% A more robust approach in the best itinerary in arterial networks consists in maximizing the probability of arriving on time instead of just minimizing the mean travel time. This is achieved by modeling travel times with 
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

% statistical distributions and taking into account the variance of the travel times. Three refinements are added to the model: a 
\backslash
emph{Stop-
\backslash
&-Go filter} that detects the stops experienced by a vehicle (mainly caused by the presence of traffic lights and obstacles), which models most of the variability of the distribution of travel times, the 
\backslash
emph{Markov Model} that models the correlations between the number of stops for consecutive links, and a 
\backslash
emph{Gaussian Markov Random Field} that captures the spatial and temporal correlations in travel times. Once the optimal parameters of the model have been estimated, the distribution of the travel time of trajectories is infered by sampling the most probable states using the 
\backslash
emph{Gibbs sampling} algorithm, and the variance is computed via a 
\backslash
emph{low rank approximation}.
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

% 
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

% add paragraph about validation
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

% 
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

% While the estimation of the parameters of the model can be achieved easily by maximizing the log-likelihoods of the observations for the 
\backslash
emph{Stop-
\backslash
&-Go filter} and 
\backslash
emph{Markov model}, the learning of the covariance matrix in the GMRF is more difficult. Partially observed random variables makes the  convergence rate partially slow and does not guarantee the positive semi-definiteness of the empirical covariance matrix. Some scalable heuristics have been developed to find a near correlation matrix but more reliable algorithms are presented in the literature such as in 
\backslash
cite{Higham2002, Qi2006}
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\end_layout

\end_body
\end_document
