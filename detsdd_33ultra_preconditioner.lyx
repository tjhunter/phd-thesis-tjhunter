#LyX file created by tex2lyx 2.0.6
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options false
\language english
\language_package none
\inputencoding auto
\fontencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\paperfontsize default
\spacing single
\use_hyperref 0
\papersize default
\use_geometry false
\use_amsmath 2
\use_esint 1
\use_mhchem 0
\use_mathdots 0
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard

%%stopskip  : marker for tim's thesis, please do not remove it :-)
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\end_layout

\begin_layout Subsection

Incremental sparsifiers
\begin_inset CommandInset label
LatexCommand label
name "sec:Incremental-sparsifiers"

\end_inset


\end_layout

\begin_layout Standard

We can do better and achieve near-linear time by using ultra-sparsifiers. The main insight of our result is that the class preconditioners presented by Spielman and Teng are based on incomplete Cholesky factorization, and hence have a determinant that is relatively easy to compute, and furthermore that they are excellent spectral preconditioners, so the procedure 
\family typewriter
PreconditionedLogDetMonteCarlo
\family default
 is efficient to apply. We reintroduce some concepts presented in 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2010"

\end_inset

 to present a self-contained result. The following paragraphs are well-known facts about Spielman-Teng preconditioners and have been presented in 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2010,Spielman2009a"

\end_inset

.
\end_layout

\begin_layout Standard

The central idea to the Spielman-Teng preconditioner is to sample 
\begin_inset Formula $\mathcal{O}\left(n\right)$
\end_inset

 edges from the graph 
\begin_inset Formula $A$
\end_inset

, to form a subgraph 
\begin_inset Formula $B$
\end_inset

 that is close to a tree (hence it is easy to compute some partial Cholesky factorization), yet it is close to the original 
\begin_inset Formula $A$
\end_inset

 is the spectral sense (
\begin_inset Formula $A\preceq B\preceq\kappa A$
\end_inset

), thanks to the additional edges. The partial Cholesky factorization is computed using the 
\family typewriter
GreedyElimination
\family default
 algorithm presented in 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2010"

\end_inset

. In order for this section to be self-contained, we include here the main results of Section 4 in 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Spielman2009a"

\end_inset

.
\end_layout

\begin_layout Standard

Consider the Laplacian matrix 
\begin_inset Formula $L_{B}$
\end_inset

 of the subgraph 
\begin_inset Formula $B$
\end_inset

. There exists an algorithm that computes the partial Cholesky factorization: 
\begin_inset Formula \[
L_{B}=PLCL^{T}P^{T}
\]
\end_inset

where: 
\end_layout

\begin_layout Itemize


\begin_inset Formula $P$
\end_inset

 is a permutation matrix 
\end_layout

\begin_layout Itemize


\begin_inset Formula $L$
\end_inset

 is a non-singular, low triangular matrix of the form 
\begin_inset Formula \[
L=\left(\begin{array}{cc}
L_{1,1} & 0\\
L_{2,1} & I_{n_{1}}
\end{array}\right)
\]
\end_inset

with the diagonal of 
\begin_inset Formula $L_{1,1}$
\end_inset

 being all ones. 
\end_layout

\begin_layout Itemize


\begin_inset Formula $C$
\end_inset

 has the form 
\begin_inset Formula \[
C=\left(\begin{array}{cc}
D_{n-n_{1}} & 0\\
0 & L_{A_{1}}
\end{array}\right)
\]
\end_inset

and every row and column of 
\begin_inset Formula $L_{A_{1}}$
\end_inset

 has at least 3 non-zero coefficients. Furthermore, 
\begin_inset Formula $L_{A_{1}}$
\end_inset

 is itself Laplacian and: 
\begin_inset Formula \[
\text{ld}\left(L_{G}\right)=\sum_{1}^{n-n_{1}}\log D_{ii}+\mbox{\text{ld}}\left(L_{A_{1}}\right)
\]
\end_inset


\end_layout

\begin_layout Standard

The exact algorithm that achieves this factorization is called 
\family typewriter
GreedyElimination
\family default
 and is presented in 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2010"

\end_inset

. Using this factorization, the PLD of the original Laplacian 
\begin_inset Formula $L_{A}$
\end_inset

 is: 
\begin_inset Formula \begin{eqnarray}
\text{ld}\left(L_{A}\right) & = & \text{ld}\left(L_{B}\right)+\text{ld}\left(B^{+}A\right)\nonumber \\
 & = & \sum_{1}^{n-n_{1}}\log D_{ii}+\mbox{\text{ld}}\left(A_{1}\right)+\text{ld}\left(B^{+}A\right)\label{eq:chain-recursion}
\end{eqnarray}
\end_inset

Thus, we are left with solving a smaller problem 
\begin_inset Formula $A_{1}$
\end_inset

, and we approximate the value of 
\begin_inset Formula $\text{ld}\left(B^{+}A\right)$
\end_inset

 using the algorithm 
\family typewriter
SampleLogDet
\family default
. ST preconditioners are appealing for this task: they guarantee that 
\begin_inset Formula $A_{1}$
\end_inset

 is substantially smaller than 
\begin_inset Formula $A$
\end_inset

, so the recursion completes in 
\begin_inset Formula $\mathcal{O}\left(\log n\right)$
\end_inset

 steps. Furthermore, computing the vector product 
\begin_inset Formula $B^{+}Ax$
\end_inset

 is itself efficient (in can be done approximated in near-linear time), so we can apply Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:preconditioning-approx"

\end_inset

. We formalize the notion of chain of preconditioners by reintroducing some material from 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2010"

\end_inset

.
\end_layout

\begin_layout Standard


\begin_inset Float algorithm
wide false
sideways false
status open


\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 Algorithm 
\series bold
UltraLogDet
\series default
(
\begin_inset Formula $A$
\end_inset

,
\begin_inset Formula $\epsilon$
\end_inset

,
\begin_inset Formula $\eta$
\end_inset

):
\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 If 
\begin_inset Formula $A$
\end_inset

 is of a small size (
\begin_inset Formula $<$
\end_inset

100), directly compute 
\begin_inset Formula $\text{ld}\left(A\right)$
\end_inset

 with a dense Cholesky factorization.
\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 Compute 
\begin_inset Formula $B=$
\end_inset


\series bold
IncrementalSparsify(
\begin_inset Formula $A$
\end_inset

)
\series default

\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 Compute 
\begin_inset Formula $D,A'=$
\end_inset


\series bold
PartialCholesky(
\begin_inset Formula $B$
\end_inset

)
\series default

\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

% TODO: change the bounds to reflect the theorem
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 
\begin_inset Formula $\eta\leftarrow\min\left(\frac{\epsilon}{8\kappa^{3}\kappa\left(B\right)},\frac{1}{2\kappa}\right)$
\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 
\begin_inset Formula $p\leftarrow8\left(\frac{1}{\epsilon}+\frac{1}{n\epsilon^{2}}\right)\log\left(\eta^{-1}\right)\log^{2}\left(\delta^{-1}\right)$
\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 
\begin_inset Formula $l\leftarrow\delta^{-1}\log\left(\frac{2}{\epsilon\delta}\right)$
\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 Compute 
\begin_inset Formula $s=$
\end_inset


\series bold
PreconditionedLogDetMonteCarlo(
\begin_inset Formula $B,A,\eta,p,l$
\end_inset

)
\series default

\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{raggedright}
\end_layout

\end_inset

 Return 
\begin_inset Formula $s+\log\left|D\right|+$
\end_inset


\series bold
UltraLogDet(
\begin_inset Formula $A'$
\end_inset

,
\begin_inset Formula $\epsilon$
\end_inset

,
\begin_inset Formula $\eta$
\end_inset

)
\series default

\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{raggedright}
\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset Caption

\begin_layout Standard

Sketch of the main algorithm
\begin_inset CommandInset label
LatexCommand label
name "alg:The-main-algorithm"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{definition}
\end_layout

\end_inset

 Definition 4.2 from 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2011"

\end_inset

. Good preconditioning chain. Let 
\begin_inset Formula $d\in\mathbb{N}^{*}$
\end_inset

, 
\begin_inset Formula $\mathcal{C}=\left\{ A_{1}=A,B_{1},A_{2},B_{2},A_{3}\dots B_{d-1},A_{d}\right\} $
\end_inset

 be a chain of graphs and 
\begin_inset Formula $\mathcal{K}=\left(\kappa_{1}\cdots\kappa_{d-1}\right)\in\mathbb{R}_{+}^{d-1}$
\end_inset

. We say that 
\begin_inset Formula $\left\{ \mathcal{C},\mathcal{K}\right\} $
\end_inset

 is a good preconditioning chain for 
\begin_inset Formula $A$
\end_inset

 if there exists 
\begin_inset Formula $\mathcal{U}=\left(\mu_{1}\cdots\mu_{d}\right)\in\mathbb{N}_{+}^{d}$
\end_inset

 so that: 
\end_layout

\begin_layout Enumerate


\begin_inset Formula $A_{i}\preceq B_{i}\preceq\kappa_{i}A_{i}$
\end_inset

 . 
\end_layout

\begin_layout Enumerate


\begin_inset Formula $A_{i+1}$
\end_inset

= 
\family typewriter
GreedyElimination
\family default

\begin_inset Formula $\left(B_{i}\right)$
\end_inset

 . 
\begin_inset ERT
status collapsed

\begin_layout Standard

% TODO: We need to explain greedy elimination somewhere
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\end_layout

\begin_layout Enumerate

The number of edges of 
\begin_inset Formula $A_{i}$
\end_inset

 is less than 
\begin_inset Formula $\mu_{i}$
\end_inset

. 
\end_layout

\begin_layout Enumerate


\begin_inset Formula $\mu_{1}=\mu_{2}=m$
\end_inset

 where 
\begin_inset Formula $m$
\end_inset

 is the number of edges of 
\begin_inset Formula $A$
\end_inset

. 
\end_layout

\begin_layout Enumerate


\begin_inset Formula $\mu_{i}/\mu_{i+1}\geq c_{r}\left\lceil \sqrt{\kappa_{i}}\right\rceil $
\end_inset

 for some constant 
\begin_inset Formula $c_{r}$
\end_inset

. 
\end_layout

\begin_layout Enumerate


\begin_inset Formula $\kappa_{i+1}\leq\kappa_{i}$
\end_inset

. 
\end_layout

\begin_layout Enumerate


\begin_inset Formula $\mu_{d}$
\end_inset

 is smaller than some fixed arbitrary constant. 
\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{definition}
\end_layout

\end_inset

 Good chains exist, as found by Koutis, Miller and Peng: 
\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{lemma}
\end_layout

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "lem:good-chain"

\end_inset

 (Lemma 4.5 from 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2011"

\end_inset

) Given a graph 
\begin_inset Formula $A$
\end_inset

, the algorithm 
\family typewriter
BuildChain
\family default

\begin_inset Formula $\left(A,p\right)$
\end_inset

 from 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2011"

\end_inset

 produces with probability 
\begin_inset Formula $1-p$
\end_inset

 a good preconditioning chain 
\begin_inset Formula $\left\{ \mathcal{C},\mathcal{K}\right\} $
\end_inset

 such that 
\begin_inset Formula $\kappa_{1}=\tilde{O}\left(\log^{2}n\right)$
\end_inset

 and 
\begin_inset Formula $\kappa_{i}=\kappa_{c}$
\end_inset

 for all 
\begin_inset Formula $i\geq2$
\end_inset

 for some constant 
\begin_inset Formula $\kappa_{c}$
\end_inset

. The length of the chain is 
\begin_inset Formula $d=\mathcal{O}\left(\log n\right)$
\end_inset

 and the algorithm runs in expected time 
\begin_inset Formula $\tilde{O}\left(m\log n\right).$
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard

%+n
\backslash
log n
\backslash
log
\backslash
log n
\backslash
right)$
\end_layout

\begin_layout Standard


\end_layout

\end_inset


\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{lemma}
\end_layout

\end_inset

 These chains furthermore can be used as good preconditioners for conjugate gradient and lead to near-linear algorithms for approximate inversion (Lemma 7.2 from 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2010"

\end_inset

). This remarkable result has been significantly strengthened in the previous years, so that SDD systems can be considered to be solved in (expected) linear time. 
\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
begin{lemma}
\end_layout

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "lem:linear-precond-existence"

\end_inset

(Theorem 4.6 from 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Koutis2011"

\end_inset

). Given 
\begin_inset Formula $A\in SDD_{n}$
\end_inset

 with 
\begin_inset Formula $m$
\end_inset

 non-zero entries, 
\begin_inset Formula $b\in\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $\nu>0$
\end_inset

, a vector 
\begin_inset Formula $x$
\end_inset

 such that 
\begin_inset Formula $\left\Vert x-A^{+}b\right\Vert _{A}<\nu\left\Vert A^{+}b\right\Vert _{A}$
\end_inset

 can be computed in expected time 
\begin_inset Formula $\tilde{O}\left(m\log n\log\left(1/\nu\right)\right)$
\end_inset

. 
\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
end{lemma}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

It should now become clear how we can combine a good chain with the Algorithm 
\family typewriter
PreconditionedLogDetMonteCarlo
\family default
. We start by building a chain. The partial Cholesky factorizations at each step of the chain provide an upper bound on 
\begin_inset Formula $\mbox{ld}\left(A\right)$
\end_inset

. We then refine this upper bound by running 
\family typewriter
Preconditioned\SpecialChar \-
LogDetMonteCarlo
\family default
 at each state of the chain to approximate 
\begin_inset Formula $\mbox{ld}\left(B_{i}^{+}A_{i}\right)$
\end_inset

 with high probability. The complete algorithm is presented in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:The-main-algorithm"

\end_inset

. We now have all the tools required to prove Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:ultra_main"

\end_inset

.
\end_layout

\begin_layout Standard


\series bold
Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:ultra_main"

\end_inset

.
\series default
 First, recall that we can consider either an SDD or its grounded Laplacian thanks to the relation 
\begin_inset Formula $\log |A|=\ld L_{A}$
\end_inset

. Call 
\begin_inset Formula $A_{1}=L_{A}$
\end_inset

 the first element of the chain. In this proof, all the matrices will be Laplacian from now on. Using Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:good-chain"

\end_inset

, consider 
\begin_inset Formula $\mathcal{C}=\left\{ A_{1}=A,B_{1},A_{2},\dots A_{d}\right\} $
\end_inset

 a good chain for 
\begin_inset Formula $A$
\end_inset

, with 
\begin_inset Formula $d=\mathcal{O}\left(\log n\right)$
\end_inset

. More precisely, since 
\begin_inset Formula $A_{i+1}$
\end_inset

= 
\family typewriter
Greedy\SpecialChar \-
Elimination
\family default

\begin_inset Formula $\left(B_{i}\right)$
\end_inset

, the Laplacian 
\begin_inset Formula $B_{i}$
\end_inset

 can be factored as: 
\begin_inset Formula \[
B_{i}=P_{i}L_{i}\left(\begin{array}{cc}
D^{\left(i\right)} & 0\\
0 & A_{i+1}
\end{array}\right)L_{i}^{T}P_{i}^{T}
\]
\end_inset

with 
\begin_inset Formula $P_{i}$
\end_inset

 a permutation matrix, 
\begin_inset Formula $L_{i}$
\end_inset

 a lower triangular matrix with 
\begin_inset Formula $1$
\end_inset

 one the diagonal and 
\begin_inset Formula $D^{\left(i\right)}$
\end_inset

a positive definite diagonal matrix. The matrix 
\begin_inset Formula $D^{\left(i\right)}$
\end_inset

 is an immediate by-product of running the algorithm 
\family typewriter
GreedyElimination
\family default
 and can be obtained when forming the chain 
\begin_inset Formula $\mathcal{C}$
\end_inset

 at no additional cost.
\end_layout

\begin_layout Standard

From the discussion at the start of the section, it is clear that 
\begin_inset Formula $\ld B_{i}=\sum_{k}\log D_{k}^{\left(i\right)}+\ld A_{i+1}$
\end_inset

. From the discussion in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Preconditioned-log-determinants"

\end_inset

, the log-determinant of 
\begin_inset Formula $A$
\end_inset

 is: 
\begin_inset Formula \begin{eqnarray*}
\log |A| & = & \ld A_{1}\\
 & = & \ld B_{1}+\ld\left(B_{1}^{+}A_{1}\right)\\
 & = & \sum_{k}\log D_{k}^{\left(1\right)}+\ld A_{2}+\ld\left(B_{1}^{+}A_{1}\right)\\
 & ... & \\
 & = & \ld A_{d}+\sum_{i=1}^{d}\left(\sum_{k}\log D_{k}^{\left(i\right)}\right)+\sum_{i=1}^{d}\ld\left(B_{i}^{+}A_{i}\right)
\end{eqnarray*}
\end_inset

The term 
\begin_inset Formula $\ld A_{d}$
\end_inset

 can be estimated by dense Cholesky factorization at cost 
\begin_inset Formula $\mathcal{O}\left(1\right)$
\end_inset

, and the diagonal Cholesky terms 
\begin_inset Formula $\sum_{k}\log D_{k}^{\left(i\right)}$
\end_inset

 are already computed from the chain. We are left with estimating the 
\begin_inset Formula $d$
\end_inset

 remainders 
\begin_inset Formula $\text{ld}\left(B_{i}^{+}A_{i}\right)$
\end_inset

. By construction, 
\begin_inset Formula $A_{i}\preceq B_{i}\preceq\kappa_{i}A_{i}$
\end_inset

 and by Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:linear-precond-existence"

\end_inset

, there exists an operator 
\begin_inset Formula $C_{i}$
\end_inset

 so that 
\begin_inset Formula $\left\Vert C_{i}\left(b\right)-B_{i}^{+}b\right\Vert _{B_{i}}<\nu\left\Vert B_{i}^{+}b\right\Vert _{B_{i}}$
\end_inset

 for all 
\begin_inset Formula $b$
\end_inset

 with a choice of relative precision 
\begin_inset Formula $\nu=\frac{\epsilon}{16\kappa_{i}^{3}\kappa\left(B_{i}\right)}$
\end_inset

.
\end_layout

\begin_layout Standard

This relative precision depends on the condition number 
\begin_inset Formula $\kappa\left(B_{i}\right)$
\end_inset

 of 
\begin_inset Formula $B_{i}$
\end_inset

. We can coarsely relate this condition number to the condition number of 
\begin_inset Formula $A_{1}$
\end_inset

by noting the following: 
\end_layout

\begin_layout Itemize

Since 
\begin_inset Formula $A_{i}\preceq B_{i}\preceq\kappa_{i}A_{i}$
\end_inset

 by construction, 
\begin_inset Formula $\kappa\left(B_{i}\right)\leq\kappa_{i}\kappa\left(A_{i}\right)$
\end_inset

 
\end_layout

\begin_layout Itemize

For diagonally dominant matrices or Laplacian matrices, the condition number of the partial Cholesky factor is bounded by the condition number of the original matrix. This can be seen by analyzing one update in the Cholesky factorization. Given a partially factorized matrix 
\begin_inset Formula $\tilde{A}=\left(\begin{array}{ccc}
I_{p} & 0 & 0\\
0 & a & b\\
0 & b^{T} & S
\end{array}\right)$
\end_inset

, after factorization, the next matrix is 
\begin_inset Formula $\left(\begin{array}{cc}
I_{p+1} & 0\\
0 & S-a^{-1}bb^{T}
\end{array}\right)$
\end_inset

. The spectrum of the Schur complement 
\begin_inset Formula $S-a^{-1}bb^{T}$
\end_inset

is bounded by the spectrum of 
\begin_inset Formula $\left(\begin{array}{cc}
a & b\\
b^{T} & S
\end{array}\right)$
\end_inset

 (see Corollary 2.3 in 
\begin_inset CommandInset citation
LatexCommand cite
after ""
key "Zhang2005"

\end_inset

) and thus its condition number is upper bounded by that of 
\begin_inset Formula $\tilde{A}$
\end_inset

. 
\end_layout

\begin_layout Standard

As a consequence, we have for all 
\begin_inset Formula $i$
\end_inset

: 
\begin_inset Formula $\kappa\left(A_{i+1}\right)\leq\kappa\left(B_{i}\right)\leq\kappa_{i}\kappa\left(A_{i}\right)\leq\prod_{j=1}^{i}\kappa_{j}\kappa\left(A_{1}\right) \\*=\tilde{O}\left(\kappa_{1}\kappa_{c}^{i-1}\kappa\left(A\right)\right)$
\end_inset

 with 
\begin_inset Formula $\kappa_{c}$
\end_inset

 the constant introduced in Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:good-chain"

\end_inset

. This coarse analysis gives us the bound: 
\begin_inset Formula \[
\kappa\left(B_{i}\right)\leq\tilde{O}\left(\kappa_{c}^{\log n}\log^{2}n~\kappa\left(A\right)\right)=\tilde{O}\left(n^{\log\kappa_{c}}\log^{2}n\ \kappa\left(A\right)\right).
\]
\end_inset

Consider the relative precision 
\begin_inset Formula $\tilde{\nu}=\tilde{\mathcal{O}}\left(n^{-\log\kappa_{c}}\log^{-8}n\frac{\epsilon}{\kappa\left(A\right)}\right)$
\end_inset

 so that 
\begin_inset Formula $\tilde{\nu}\leq\nu_{i}$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

. Constructing the operator 
\begin_inset Formula $C_{i}$
\end_inset

 is a byproduct of forming the chain 
\emph on

\begin_inset Formula $\mathcal{C}$
\end_inset

. 
\emph default
By Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:det-sampling-theorem"

\end_inset

, each remainder 
\begin_inset Formula $\text{ld}\left(B_{i}^{+}A_{i}\right)$
\end_inset

 can be approximated to precision 
\begin_inset Formula $\epsilon$
\end_inset

 with probability at least 
\begin_inset Formula $1-\eta$
\end_inset

 using Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:SampleLogDet"

\end_inset

. Furthermore, this algorithm works in expected time 
\begin_inset Formula \begin{eqnarray*}
 &  & \tilde{O}\left(m\log n\log\left(1/\tilde{\nu}\right)\kappa_{1}\left(\frac{1}{\epsilon}+\frac{1}{n\epsilon^{2}}\right)\log\left(\frac{n\kappa_{1}}{\tilde{\nu}}\right)\log^{2}\left(\kappa_{1}\right)\log\left(\eta^{-1}\right)\right)\\
 &  & =\tilde{O}\left(m\log^{3}n\left(\frac{1}{\epsilon}+\frac{1}{n\epsilon^{2}}\right)\log^{2}\left(\frac{n\kappa\left(A\right)}{\epsilon}\right)\log\left(\eta^{-1}\right)\right)
\end{eqnarray*}
\end_inset

By a union bound, the result also holds on the sum of all the 
\begin_inset Formula $\log n$
\end_inset

 approximations of the remainders. We can simplify this bound a little by assuming that 
\begin_inset Formula $\epsilon\geq n^{-1}$
\end_inset

, which then becomes 
\begin_inset Formula $\tilde{O}\left(m\epsilon^{-1}\log^{3}n\log^{2}\left(\frac{n\kappa\left(A\right)}{\epsilon}\right)\log\left(\eta^{-1}\right)\right)$
\end_inset

. 
\end_layout

\end_body
\end_document
